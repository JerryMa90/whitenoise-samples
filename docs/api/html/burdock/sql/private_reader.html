<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>burdock.sql.private_reader API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>burdock.sql.private_reader</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import math
import numpy as np
from .private_rewriter import Rewriter
from .parse import QueryParser

from burdock.ast.expressions import sql as ast

from burdock.mechanisms.laplace import Laplace
from burdock.mechanisms.gaussian import Gaussian
from burdock.report import Interval, Intervals, Result
from burdock.reader.rowset import TypedRowset


class PrivateReader:
    &#34;&#34;&#34;Executes SQL queries against tabular data sources and returns differentially private results 
    &#34;&#34;&#34;
    def __init__(self, reader, metadata, epsilon=1.0, delta=10E-16, interval_widths=None, options=None):
        &#34;&#34;&#34;Create a new private reader.

            :param reader: The data reader to wrap, such as a SqlServerReader, PandasReader, or SparkReader
                The PrivateReader intercepts queries to the underlying reader and ensures differential privacy.
            :param metadata: The CollectionMetadata object with information about all tables referenced in this query
            :param epsilon: The privacy budget to spend for each column in the query
            :param delta: The delta privacy parameter
            :param interval_widths: If supplied, returns confidence intervals of the specified width, e.g. [0.95, 0.75]
            :param options: A PrivateReaderOptions with flags that change the behavior of the privacy
                engine.
        &#34;&#34;&#34;
        self.options = options if options is not None else PrivateReaderOptions()
        self.reader = reader
        self.metadata = metadata
        self.rewriter = Rewriter(metadata)
        self.epsilon = epsilon
        self.delta = delta
        self.interval_widths = interval_widths
        self._cached_exact = None
        self._cached_ast = None
        self.refresh_options()

    def refresh_options(self):
        self.rewriter = Rewriter(self.metadata)
        self.metadata.compare = self.reader.compare
        self.rewriter.options.row_privacy = self.options.row_privacy
        self.rewriter.options.reservoir_sample = self.options.reservoir_sample
        self.rewriter.options.clamp_columns = self.options.clamp_columns
        self.rewriter.options.max_contrib = self.options.max_contrib

    def parse_query_string(self, query_string):
        queries = QueryParser(self.metadata).queries(query_string)
        if len(queries) &gt; 1:
            raise ValueError(&#34;Too many queries provided.  We can only execute one query at a time.&#34;)
        elif len(queries) == 0:
            return []
        return queries[0]

    def rewrite(self, query_string):
        query = self.parse_query_string(query_string)
        return self.rewrite_ast(query)

    def rewrite_ast(self, query):
        query_max_contrib = query.max_ids
        if self.options.max_contrib is None or self.options.max_contrib &gt; query_max_contrib:
            self.options.max_contrib = query_max_contrib        

        self.refresh_options()
        query = self.rewriter.query(query)
        subquery = query.source.relations[0].primary.query
        return (subquery, query)

    def get_privacy_cost(self, query_string):
        self.refresh_options()
        subquery, query = self.rewrite(query_string)
        return subquery.numeric_symbols()

    def execute(self, query_string):
        &#34;&#34;&#34;Executes a query and returns a recordset that is differentially private.

        Follows ODBC and DB_API convention of consuming query as a string and returning
        recordset as tuples.  This is useful for cases where existing DB_API clients
        want to swap out API calls with minimal changes.

        :param query_string: A query string in SQL syntax
        :return: A recordset structured as an array of tuples, where each tuple
         represents a row, and each item in the tuple is typed.  The first row should
         contain column names.
        &#34;&#34;&#34;
        trs = self.execute_typed(query_string)
        return trs.rows()

    def execute_typed(self, query_string):
        &#34;&#34;&#34;Executes a query and returns a differentially private typed recordset.

        This is the typed version of execute.

        :param query_string: A query in SQL syntax
        :return: A typed recordset, where columns can be referenced by name.
        &#34;&#34;&#34;
        query = self.parse_query_string(query_string)
        return self.execute_ast_typed(query)

    def _execute_ast(self, query, cache_exact=False):
        if isinstance(query, str):
            raise ValueError(&#34;Please pass AST to _execute.&#34;)

        subquery, query = self.rewrite_ast(query)
        max_contrib = self.options.max_contrib if self.options.max_contrib is not None else 1
        self.tau = max_contrib * (1- ( math.log(2 * self.delta / max_contrib) / self.epsilon  ))

        syms = subquery.all_symbols()
        source_col_names = [s[0] for s in syms]

        # list of sensitivities in column order
        sens = [s[1].sensitivity() for s in syms]

        # tell which are counts, in column order
        is_count = [s[1].is_count for s in syms]

        # set sensitivity to None if the column is a grouping key
        if subquery.agg is not None:
            group_keys = [ge.expression.name if hasattr(ge.expression, &#39;name&#39;) else None for ge in subquery.agg.groupingExpressions]
        else:
            group_keys = []
        is_group_key = [colname in group_keys for colname in [s[0] for s in syms]]
        for idx in range(len(sens)):
            if is_group_key[idx]:
                sens[idx] = None

        kc_pos = None
        kcc_pos = []
        for idx in range(len(syms)):
            sname, sym = syms[idx]
            if sname == &#39;keycount&#39;:
                kc_pos = idx
            elif sym.is_key_count:
                kcc_pos.append(idx)
        if kc_pos is None and len(kcc_pos) &gt; 0:
            kc_pos = kcc_pos.pop()

        # make a list of mechanisms in column order
        mechs = [Gaussian(self.epsilon, self.delta, s, max_contrib, self.interval_widths) if s is not None else None for s in sens]

        # execute the subquery against the backend and load in tuples
        if cache_exact:
            # we only execute the exact query once
            if self._cached_exact is not None:
                if subquery == self._cached_ast:
                    db_rs = self._cached_exact
                else:
                    raise ValueError(&#34;Cannot run different query against cached result.  Make a new PrivateReader or else clear the cache with cache = False&#34;)
            else:
                db_rs = self.reader.execute_ast(subquery)
                self._cached_exact = list(db_rs)
                self._cached_ast = subquery
        else:
            self.cached_exact = None
            self.cached_ast = None
            db_rs = self.reader.execute_ast(subquery)

        clamp_counts = self.options.clamp_counts
        def process_row(row_in):
            # pull out tuple values
            row = [v for v in row_in]
            # set null to 0 before adding noise
            for idx in range(len(row)):
                if sens[idx] is not None and row[idx] is None:
                    row[idx] = 0.0
            # call all mechanisms to add noise
            out_row = [noise.release([v]).values[0] if noise is not None else v for noise, v in zip(mechs, row)]
            # ensure all key counts are the same
            for idx in kcc_pos:
                out_row[idx] = out_row[kc_pos]
            # clamp counts to be non-negative
            if clamp_counts:
                for idx in range(len(row)):
                    if is_count[idx] and out_row[idx] &lt; 0:
                        out_row[idx] = 0
            return out_row

        if hasattr(db_rs, &#39;rdd&#39;):
            # it&#39;s a dataframe
            out = db_rs.rdd.map(process_row)
        elif hasattr(db_rs, &#39;map&#39;):
            # it&#39;s an RDD
            out = db_rs.map(process_row)
        else:
            out = map(process_row, db_rs[1:])

        if subquery.agg is not None and self.options.censor_dims:
            if hasattr(out, &#39;filter&#39;):
                # it&#39;s an RDD
                tau = self.tau
                out = out.filter(lambda row: row[kc_pos] &gt; tau)
            else:
                out = filter(lambda row: row[kc_pos] &gt; self.tau, out)

        # get column information for outer query
        out_syms = query.all_symbols()
        out_types = [s[1].type() for s in out_syms]
        out_colnames = [s[0] for s in out_syms]


        def convert(val, type):
            if type == &#39;string&#39; or type == &#39;unknown&#39;:
                return str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;)
            elif type == &#39;int&#39;:
                return int(float(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;)))
            elif type == &#39;float&#39;:
                return float(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;))
            elif type == &#39;boolean&#39;:
                if isinstance(val, int):
                    return val != 0
                else:
                    return bool(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;))
            else:
                raise ValueError(&#34;Can&#39;t convert type &#34; + type)

        def process_out_row(row):
            bindings = dict((name.lower(), val ) for name, val in zip(source_col_names, row))
            row = [c.expression.evaluate(bindings) for c in query.select.namedExpressions]
            return [convert(val, type) for val, type in zip(row, out_types)]
    
        if hasattr(out, &#39;map&#39;):
            # it&#39;s an RDD
            out = out.map(process_out_row)
        else:
            out = map(process_out_row, out)

        # sort it if necessary
        if query.order is not None:
            sort_fields = []
            for si in query.order.sortItems:
                if type(si.expression) is not ast.Column:
                    raise ValueError(&#34;We only know how to sort by column names right now&#34;)
                colname = si.expression.name.lower()
                if colname not in out_colnames:
                    raise ValueError(&#34;Can&#39;t sort by {0}, because it&#39;s not in output columns: {1}&#34;.format(colname, out_colnames))
                colidx = out_colnames.index(colname)
                desc = False
                if si.order is not None and si.order.lower() == &#34;desc&#34;:
                    desc = True
                if desc and not (out_types[colidx] in [&#34;int&#34;, &#34;float&#34;, &#34;boolean&#34;]):
                    raise ValueError(&#34;We don&#39;t know how to sort descending by &#34; + out_types[colidx])
                sf = (desc, colidx)
                sort_fields.append(sf)

            def sort_func(row):
                return tuple([row[idx] if not desc else not row[idx] if out_types[idx] == &#34;boolean&#34; else -row[idx] for desc, idx in sort_fields])

            if hasattr(out, &#39;sortBy&#39;):
                out = out.sortBy(sort_func)
            else:
                out = sorted(out, key=sort_func)

        # output it
        if hasattr(out, &#39;toDF&#39;):
            # Pipeline RDD
            return out.toDF(out_colnames)
        elif hasattr(out, &#39;map&#39;):
            # Bare RDD
            return out
        else:
            return TypedRowset([out_colnames] + list(out), out_types)

    def execute_ast(self, query):
        &#34;&#34;&#34;Executes an AST representing a SQL query

        :param query: A SQL query in AST form
        :return: A recordset formatted as tuples for rows, with first row having column names
        &#34;&#34;&#34;
        if isinstance(query, str):
            raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)
        trs = self.execute_ast_typed(query)
        return trs.rows()

    def execute_ast_typed(self, query):
        &#34;&#34;&#34;Executes an AST representing a SQL query, returning typed recordset

        :param query: A SQL query in AST form
        :return: A typed recordset
        &#34;&#34;&#34;
        if isinstance(query, str):
            raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)

        return self._execute_ast(query, False)

class PrivateReaderOptions:
    &#34;&#34;&#34;Options that control privacy behavior&#34;&#34;&#34;
    def __init__(self, 
        censor_dims=True, 
        clamp_counts=True, 
        reservoir_sample=True,
        clamp_columns=True,
        row_privacy=False,
        max_contrib=None):
        &#34;&#34;&#34;Initialize with options.
        :param censor_dims: boolean, set to False if you know that small dimensions cannot expose privacy
        :param clamp_counts: boolean, set to False to allow noisy counts to be negative
        :param reservoir_sample: boolean, set to False if the data collection will never have more than max_contrib record per individual
        :param clamp_columns: boolean, set to False to allow values that exceed lower and higher limit specified in metadata.  May impact privacy
        :param row_privacy: boolean, True if each row is a separate individual
        :param max_contrib: int, set to override the metadata-supplied limit of per-user
          contribution.  May only revise down; metadata takes precedence if limit is smaller.&#34;&#34;&#34;
        self.censor_dims = censor_dims
        self.clamp_counts = clamp_counts
        self.reservoir_sample = reservoir_sample
        self.clamp_columns = clamp_columns
        self.row_privacy = row_privacy
        self.max_contrib = max_contrib</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="burdock.sql.private_reader.PrivateReader"><code class="flex name class">
<span>class <span class="ident">PrivateReader</span></span>
<span>(</span><span>reader, metadata, epsilon=1.0, delta=1e-15, interval_widths=None, options=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Executes SQL queries against tabular data sources and returns differentially private results </p>
<p>Create a new private reader.</p>
<p>:param reader: The data reader to wrap, such as a SqlServerReader, PandasReader, or SparkReader
The PrivateReader intercepts queries to the underlying reader and ensures differential privacy.
:param metadata: The CollectionMetadata object with information about all tables referenced in this query
:param epsilon: The privacy budget to spend for each column in the query
:param delta: The delta privacy parameter
:param interval_widths: If supplied, returns confidence intervals of the specified width, e.g. [0.95, 0.75]
:param options: A PrivateReaderOptions with flags that change the behavior of the privacy
engine.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PrivateReader:
    &#34;&#34;&#34;Executes SQL queries against tabular data sources and returns differentially private results 
    &#34;&#34;&#34;
    def __init__(self, reader, metadata, epsilon=1.0, delta=10E-16, interval_widths=None, options=None):
        &#34;&#34;&#34;Create a new private reader.

            :param reader: The data reader to wrap, such as a SqlServerReader, PandasReader, or SparkReader
                The PrivateReader intercepts queries to the underlying reader and ensures differential privacy.
            :param metadata: The CollectionMetadata object with information about all tables referenced in this query
            :param epsilon: The privacy budget to spend for each column in the query
            :param delta: The delta privacy parameter
            :param interval_widths: If supplied, returns confidence intervals of the specified width, e.g. [0.95, 0.75]
            :param options: A PrivateReaderOptions with flags that change the behavior of the privacy
                engine.
        &#34;&#34;&#34;
        self.options = options if options is not None else PrivateReaderOptions()
        self.reader = reader
        self.metadata = metadata
        self.rewriter = Rewriter(metadata)
        self.epsilon = epsilon
        self.delta = delta
        self.interval_widths = interval_widths
        self._cached_exact = None
        self._cached_ast = None
        self.refresh_options()

    def refresh_options(self):
        self.rewriter = Rewriter(self.metadata)
        self.metadata.compare = self.reader.compare
        self.rewriter.options.row_privacy = self.options.row_privacy
        self.rewriter.options.reservoir_sample = self.options.reservoir_sample
        self.rewriter.options.clamp_columns = self.options.clamp_columns
        self.rewriter.options.max_contrib = self.options.max_contrib

    def parse_query_string(self, query_string):
        queries = QueryParser(self.metadata).queries(query_string)
        if len(queries) &gt; 1:
            raise ValueError(&#34;Too many queries provided.  We can only execute one query at a time.&#34;)
        elif len(queries) == 0:
            return []
        return queries[0]

    def rewrite(self, query_string):
        query = self.parse_query_string(query_string)
        return self.rewrite_ast(query)

    def rewrite_ast(self, query):
        query_max_contrib = query.max_ids
        if self.options.max_contrib is None or self.options.max_contrib &gt; query_max_contrib:
            self.options.max_contrib = query_max_contrib        

        self.refresh_options()
        query = self.rewriter.query(query)
        subquery = query.source.relations[0].primary.query
        return (subquery, query)

    def get_privacy_cost(self, query_string):
        self.refresh_options()
        subquery, query = self.rewrite(query_string)
        return subquery.numeric_symbols()

    def execute(self, query_string):
        &#34;&#34;&#34;Executes a query and returns a recordset that is differentially private.

        Follows ODBC and DB_API convention of consuming query as a string and returning
        recordset as tuples.  This is useful for cases where existing DB_API clients
        want to swap out API calls with minimal changes.

        :param query_string: A query string in SQL syntax
        :return: A recordset structured as an array of tuples, where each tuple
         represents a row, and each item in the tuple is typed.  The first row should
         contain column names.
        &#34;&#34;&#34;
        trs = self.execute_typed(query_string)
        return trs.rows()

    def execute_typed(self, query_string):
        &#34;&#34;&#34;Executes a query and returns a differentially private typed recordset.

        This is the typed version of execute.

        :param query_string: A query in SQL syntax
        :return: A typed recordset, where columns can be referenced by name.
        &#34;&#34;&#34;
        query = self.parse_query_string(query_string)
        return self.execute_ast_typed(query)

    def _execute_ast(self, query, cache_exact=False):
        if isinstance(query, str):
            raise ValueError(&#34;Please pass AST to _execute.&#34;)

        subquery, query = self.rewrite_ast(query)
        max_contrib = self.options.max_contrib if self.options.max_contrib is not None else 1
        self.tau = max_contrib * (1- ( math.log(2 * self.delta / max_contrib) / self.epsilon  ))

        syms = subquery.all_symbols()
        source_col_names = [s[0] for s in syms]

        # list of sensitivities in column order
        sens = [s[1].sensitivity() for s in syms]

        # tell which are counts, in column order
        is_count = [s[1].is_count for s in syms]

        # set sensitivity to None if the column is a grouping key
        if subquery.agg is not None:
            group_keys = [ge.expression.name if hasattr(ge.expression, &#39;name&#39;) else None for ge in subquery.agg.groupingExpressions]
        else:
            group_keys = []
        is_group_key = [colname in group_keys for colname in [s[0] for s in syms]]
        for idx in range(len(sens)):
            if is_group_key[idx]:
                sens[idx] = None

        kc_pos = None
        kcc_pos = []
        for idx in range(len(syms)):
            sname, sym = syms[idx]
            if sname == &#39;keycount&#39;:
                kc_pos = idx
            elif sym.is_key_count:
                kcc_pos.append(idx)
        if kc_pos is None and len(kcc_pos) &gt; 0:
            kc_pos = kcc_pos.pop()

        # make a list of mechanisms in column order
        mechs = [Gaussian(self.epsilon, self.delta, s, max_contrib, self.interval_widths) if s is not None else None for s in sens]

        # execute the subquery against the backend and load in tuples
        if cache_exact:
            # we only execute the exact query once
            if self._cached_exact is not None:
                if subquery == self._cached_ast:
                    db_rs = self._cached_exact
                else:
                    raise ValueError(&#34;Cannot run different query against cached result.  Make a new PrivateReader or else clear the cache with cache = False&#34;)
            else:
                db_rs = self.reader.execute_ast(subquery)
                self._cached_exact = list(db_rs)
                self._cached_ast = subquery
        else:
            self.cached_exact = None
            self.cached_ast = None
            db_rs = self.reader.execute_ast(subquery)

        clamp_counts = self.options.clamp_counts
        def process_row(row_in):
            # pull out tuple values
            row = [v for v in row_in]
            # set null to 0 before adding noise
            for idx in range(len(row)):
                if sens[idx] is not None and row[idx] is None:
                    row[idx] = 0.0
            # call all mechanisms to add noise
            out_row = [noise.release([v]).values[0] if noise is not None else v for noise, v in zip(mechs, row)]
            # ensure all key counts are the same
            for idx in kcc_pos:
                out_row[idx] = out_row[kc_pos]
            # clamp counts to be non-negative
            if clamp_counts:
                for idx in range(len(row)):
                    if is_count[idx] and out_row[idx] &lt; 0:
                        out_row[idx] = 0
            return out_row

        if hasattr(db_rs, &#39;rdd&#39;):
            # it&#39;s a dataframe
            out = db_rs.rdd.map(process_row)
        elif hasattr(db_rs, &#39;map&#39;):
            # it&#39;s an RDD
            out = db_rs.map(process_row)
        else:
            out = map(process_row, db_rs[1:])

        if subquery.agg is not None and self.options.censor_dims:
            if hasattr(out, &#39;filter&#39;):
                # it&#39;s an RDD
                tau = self.tau
                out = out.filter(lambda row: row[kc_pos] &gt; tau)
            else:
                out = filter(lambda row: row[kc_pos] &gt; self.tau, out)

        # get column information for outer query
        out_syms = query.all_symbols()
        out_types = [s[1].type() for s in out_syms]
        out_colnames = [s[0] for s in out_syms]


        def convert(val, type):
            if type == &#39;string&#39; or type == &#39;unknown&#39;:
                return str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;)
            elif type == &#39;int&#39;:
                return int(float(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;)))
            elif type == &#39;float&#39;:
                return float(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;))
            elif type == &#39;boolean&#39;:
                if isinstance(val, int):
                    return val != 0
                else:
                    return bool(str(val).replace(&#39;&#34;&#39;, &#39;&#39;).replace(&#34;&#39;&#34;, &#39;&#39;))
            else:
                raise ValueError(&#34;Can&#39;t convert type &#34; + type)

        def process_out_row(row):
            bindings = dict((name.lower(), val ) for name, val in zip(source_col_names, row))
            row = [c.expression.evaluate(bindings) for c in query.select.namedExpressions]
            return [convert(val, type) for val, type in zip(row, out_types)]
    
        if hasattr(out, &#39;map&#39;):
            # it&#39;s an RDD
            out = out.map(process_out_row)
        else:
            out = map(process_out_row, out)

        # sort it if necessary
        if query.order is not None:
            sort_fields = []
            for si in query.order.sortItems:
                if type(si.expression) is not ast.Column:
                    raise ValueError(&#34;We only know how to sort by column names right now&#34;)
                colname = si.expression.name.lower()
                if colname not in out_colnames:
                    raise ValueError(&#34;Can&#39;t sort by {0}, because it&#39;s not in output columns: {1}&#34;.format(colname, out_colnames))
                colidx = out_colnames.index(colname)
                desc = False
                if si.order is not None and si.order.lower() == &#34;desc&#34;:
                    desc = True
                if desc and not (out_types[colidx] in [&#34;int&#34;, &#34;float&#34;, &#34;boolean&#34;]):
                    raise ValueError(&#34;We don&#39;t know how to sort descending by &#34; + out_types[colidx])
                sf = (desc, colidx)
                sort_fields.append(sf)

            def sort_func(row):
                return tuple([row[idx] if not desc else not row[idx] if out_types[idx] == &#34;boolean&#34; else -row[idx] for desc, idx in sort_fields])

            if hasattr(out, &#39;sortBy&#39;):
                out = out.sortBy(sort_func)
            else:
                out = sorted(out, key=sort_func)

        # output it
        if hasattr(out, &#39;toDF&#39;):
            # Pipeline RDD
            return out.toDF(out_colnames)
        elif hasattr(out, &#39;map&#39;):
            # Bare RDD
            return out
        else:
            return TypedRowset([out_colnames] + list(out), out_types)

    def execute_ast(self, query):
        &#34;&#34;&#34;Executes an AST representing a SQL query

        :param query: A SQL query in AST form
        :return: A recordset formatted as tuples for rows, with first row having column names
        &#34;&#34;&#34;
        if isinstance(query, str):
            raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)
        trs = self.execute_ast_typed(query)
        return trs.rows()

    def execute_ast_typed(self, query):
        &#34;&#34;&#34;Executes an AST representing a SQL query, returning typed recordset

        :param query: A SQL query in AST form
        :return: A typed recordset
        &#34;&#34;&#34;
        if isinstance(query, str):
            raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)

        return self._execute_ast(query, False)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="burdock.sql.private_reader.PrivateReader.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, query_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Executes a query and returns a recordset that is differentially private.</p>
<p>Follows ODBC and DB_API convention of consuming query as a string and returning
recordset as tuples.
This is useful for cases where existing DB_API clients
want to swap out API calls with minimal changes.</p>
<p>:param query_string: A query string in SQL syntax
:return: A recordset structured as an array of tuples, where each tuple
represents a row, and each item in the tuple is typed.
The first row should
contain column names.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, query_string):
    &#34;&#34;&#34;Executes a query and returns a recordset that is differentially private.

    Follows ODBC and DB_API convention of consuming query as a string and returning
    recordset as tuples.  This is useful for cases where existing DB_API clients
    want to swap out API calls with minimal changes.

    :param query_string: A query string in SQL syntax
    :return: A recordset structured as an array of tuples, where each tuple
     represents a row, and each item in the tuple is typed.  The first row should
     contain column names.
    &#34;&#34;&#34;
    trs = self.execute_typed(query_string)
    return trs.rows()</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.execute_ast"><code class="name flex">
<span>def <span class="ident">execute_ast</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"><p>Executes an AST representing a SQL query</p>
<p>:param query: A SQL query in AST form
:return: A recordset formatted as tuples for rows, with first row having column names</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_ast(self, query):
    &#34;&#34;&#34;Executes an AST representing a SQL query

    :param query: A SQL query in AST form
    :return: A recordset formatted as tuples for rows, with first row having column names
    &#34;&#34;&#34;
    if isinstance(query, str):
        raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)
    trs = self.execute_ast_typed(query)
    return trs.rows()</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.execute_ast_typed"><code class="name flex">
<span>def <span class="ident">execute_ast_typed</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"><p>Executes an AST representing a SQL query, returning typed recordset</p>
<p>:param query: A SQL query in AST form
:return: A typed recordset</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_ast_typed(self, query):
    &#34;&#34;&#34;Executes an AST representing a SQL query, returning typed recordset

    :param query: A SQL query in AST form
    :return: A typed recordset
    &#34;&#34;&#34;
    if isinstance(query, str):
        raise ValueError(&#34;Please pass ASTs to execute_typed.  To execute strings, use execute.&#34;)

    return self._execute_ast(query, False)</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.execute_typed"><code class="name flex">
<span>def <span class="ident">execute_typed</span></span>(<span>self, query_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Executes a query and returns a differentially private typed recordset.</p>
<p>This is the typed version of execute.</p>
<p>:param query_string: A query in SQL syntax
:return: A typed recordset, where columns can be referenced by name.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_typed(self, query_string):
    &#34;&#34;&#34;Executes a query and returns a differentially private typed recordset.

    This is the typed version of execute.

    :param query_string: A query in SQL syntax
    :return: A typed recordset, where columns can be referenced by name.
    &#34;&#34;&#34;
    query = self.parse_query_string(query_string)
    return self.execute_ast_typed(query)</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.get_privacy_cost"><code class="name flex">
<span>def <span class="ident">get_privacy_cost</span></span>(<span>self, query_string)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_privacy_cost(self, query_string):
    self.refresh_options()
    subquery, query = self.rewrite(query_string)
    return subquery.numeric_symbols()</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.parse_query_string"><code class="name flex">
<span>def <span class="ident">parse_query_string</span></span>(<span>self, query_string)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_query_string(self, query_string):
    queries = QueryParser(self.metadata).queries(query_string)
    if len(queries) &gt; 1:
        raise ValueError(&#34;Too many queries provided.  We can only execute one query at a time.&#34;)
    elif len(queries) == 0:
        return []
    return queries[0]</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.refresh_options"><code class="name flex">
<span>def <span class="ident">refresh_options</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh_options(self):
    self.rewriter = Rewriter(self.metadata)
    self.metadata.compare = self.reader.compare
    self.rewriter.options.row_privacy = self.options.row_privacy
    self.rewriter.options.reservoir_sample = self.options.reservoir_sample
    self.rewriter.options.clamp_columns = self.options.clamp_columns
    self.rewriter.options.max_contrib = self.options.max_contrib</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.rewrite"><code class="name flex">
<span>def <span class="ident">rewrite</span></span>(<span>self, query_string)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rewrite(self, query_string):
    query = self.parse_query_string(query_string)
    return self.rewrite_ast(query)</code></pre>
</details>
</dd>
<dt id="burdock.sql.private_reader.PrivateReader.rewrite_ast"><code class="name flex">
<span>def <span class="ident">rewrite_ast</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rewrite_ast(self, query):
    query_max_contrib = query.max_ids
    if self.options.max_contrib is None or self.options.max_contrib &gt; query_max_contrib:
        self.options.max_contrib = query_max_contrib        

    self.refresh_options()
    query = self.rewriter.query(query)
    subquery = query.source.relations[0].primary.query
    return (subquery, query)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="burdock.sql.private_reader.PrivateReaderOptions"><code class="flex name class">
<span>class <span class="ident">PrivateReaderOptions</span></span>
<span>(</span><span>censor_dims=True, clamp_counts=True, reservoir_sample=True, clamp_columns=True, row_privacy=False, max_contrib=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Options that control privacy behavior</p>
<p>Initialize with options.
:param censor_dims: boolean, set to False if you know that small dimensions cannot expose privacy
:param clamp_counts: boolean, set to False to allow noisy counts to be negative
:param reservoir_sample: boolean, set to False if the data collection will never have more than max_contrib record per individual
:param clamp_columns: boolean, set to False to allow values that exceed lower and higher limit specified in metadata.
May impact privacy
:param row_privacy: boolean, True if each row is a separate individual
:param max_contrib: int, set to override the metadata-supplied limit of per-user
contribution.
May only revise down; metadata takes precedence if limit is smaller.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PrivateReaderOptions:
    &#34;&#34;&#34;Options that control privacy behavior&#34;&#34;&#34;
    def __init__(self, 
        censor_dims=True, 
        clamp_counts=True, 
        reservoir_sample=True,
        clamp_columns=True,
        row_privacy=False,
        max_contrib=None):
        &#34;&#34;&#34;Initialize with options.
        :param censor_dims: boolean, set to False if you know that small dimensions cannot expose privacy
        :param clamp_counts: boolean, set to False to allow noisy counts to be negative
        :param reservoir_sample: boolean, set to False if the data collection will never have more than max_contrib record per individual
        :param clamp_columns: boolean, set to False to allow values that exceed lower and higher limit specified in metadata.  May impact privacy
        :param row_privacy: boolean, True if each row is a separate individual
        :param max_contrib: int, set to override the metadata-supplied limit of per-user
          contribution.  May only revise down; metadata takes precedence if limit is smaller.&#34;&#34;&#34;
        self.censor_dims = censor_dims
        self.clamp_counts = clamp_counts
        self.reservoir_sample = reservoir_sample
        self.clamp_columns = clamp_columns
        self.row_privacy = row_privacy
        self.max_contrib = max_contrib</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="burdock.sql" href="index.html">burdock.sql</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="burdock.sql.private_reader.PrivateReader" href="#burdock.sql.private_reader.PrivateReader">PrivateReader</a></code></h4>
<ul class="two-column">
<li><code><a title="burdock.sql.private_reader.PrivateReader.execute" href="#burdock.sql.private_reader.PrivateReader.execute">execute</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.execute_ast" href="#burdock.sql.private_reader.PrivateReader.execute_ast">execute_ast</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.execute_ast_typed" href="#burdock.sql.private_reader.PrivateReader.execute_ast_typed">execute_ast_typed</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.execute_typed" href="#burdock.sql.private_reader.PrivateReader.execute_typed">execute_typed</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.get_privacy_cost" href="#burdock.sql.private_reader.PrivateReader.get_privacy_cost">get_privacy_cost</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.parse_query_string" href="#burdock.sql.private_reader.PrivateReader.parse_query_string">parse_query_string</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.refresh_options" href="#burdock.sql.private_reader.PrivateReader.refresh_options">refresh_options</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.rewrite" href="#burdock.sql.private_reader.PrivateReader.rewrite">rewrite</a></code></li>
<li><code><a title="burdock.sql.private_reader.PrivateReader.rewrite_ast" href="#burdock.sql.private_reader.PrivateReader.rewrite_ast">rewrite_ast</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="burdock.sql.private_reader.PrivateReaderOptions" href="#burdock.sql.private_reader.PrivateReaderOptions">PrivateReaderOptions</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>